apiVersion: v1
kind: List
items:
# Prometheus Service Account
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai

# Prometheus RBAC
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: prometheus
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  rules:
  - apiGroups: [""]
    resources: ["nodes", "nodes/proxy", "services", "endpoints", "pods"]
    verbs: ["get", "list", "watch"]

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus
  subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring

# Prometheus ConfigMap
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus-config
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  data:
    prometheus.yml: |
      global:
        scrape_interval: 15s
        evaluation_interval: 15s
        external_labels:
          environment: production
          app: customer-success-ai

      scrape_configs:
        - job_name: 'kubernetes-nodes'
          kubernetes_sd_configs:
            - role: node
          relabel_configs:
            - source_labels: [__address__]
              regex: '(.*):10250'
              replacement: '${1}:9100'
              target_label: __address__
              action: replace

        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
            - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true

        - job_name: 'kubernetes-services'
          kubernetes_sd_configs:
            - role: service
          relabel_configs:
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
              action: keep
              regex: true

# Prometheus Deployment
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: prometheus
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
      spec:
        serviceAccountName: prometheus
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
          fsGroup: 65534
        containers:
        - name: prometheus
          image: prom/prometheus:v2.45.0
          args:
            - "--config.file=/etc/prometheus/prometheus.yml"
            - "--storage.tsdb.retention.time=15d"
            - "--web.enable-lifecycle"
          ports:
            - containerPort: 9090
              name: http
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: storage
              mountPath: /prometheus
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: http
            initialDelaySeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /-/ready
              port: http
            initialDelaySeconds: 15
            timeoutSeconds: 5
        volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: storage
          emptyDir: {}

# Prometheus Service
- apiVersion: v1
  kind: Service
  metadata:
    name: prometheus
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
    annotations:
      prometheus.io/scrape: "true"
  spec:
    selector:
      app: prometheus
    ports:
    - port: 9090
      targetPort: 9090
      name: http

# Node Exporter DaemonSet
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: node-exporter
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  spec:
    selector:
      matchLabels:
        app: node-exporter
    template:
      metadata:
        labels:
          app: node-exporter
      spec:
        hostNetwork: true
        hostPID: true
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        containers:
        - name: node-exporter
          image: prom/node-exporter:v1.6.0
          args:
            - "--path.procfs=/host/proc"
            - "--path.sysfs=/host/sys"
          ports:
            - containerPort: 9100
              protocol: TCP
          resources:
            limits:
              cpu: 250m
              memory: 180Mi
            requests:
              cpu: 102m
              memory: 180Mi
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly: true
            - name: sys
              mountPath: /host/sys
              readOnly: true
        volumes:
          - name: proc
            hostPath:
              path: /proc
          - name: sys
            hostPath:
              path: /sys

# AlertManager ConfigMap
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: alertmanager-config
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  data:
    alertmanager.yml: |
      global:
        resolve_timeout: 5m
      route:
        group_by: ['alertname', 'cluster', 'service']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        receiver: 'default'
      receivers:
      - name: 'default'
        webhook_configs:
        - url: 'http://notification-service:8080/alerts'

# AlertManager Deployment
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: alertmanager
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: alertmanager
    template:
      metadata:
        labels:
          app: alertmanager
      spec:
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        containers:
        - name: alertmanager
          image: prom/alertmanager:v0.25.0
          args:
            - "--config.file=/etc/alertmanager/alertmanager.yml"
            - "--storage.path=/alertmanager"
          ports:
            - containerPort: 9093
              name: http
          resources:
            limits:
              cpu: 100m
              memory: 256Mi
            requests:
              cpu: 50m
              memory: 128Mi
          volumeMounts:
            - name: config
              mountPath: /etc/alertmanager
            - name: storage
              mountPath: /alertmanager
        volumes:
        - name: config
          configMap:
            name: alertmanager-config
        - name: storage
          emptyDir: {}

# AlertManager Service
- apiVersion: v1
  kind: Service
  metadata:
    name: alertmanager
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  spec:
    selector:
      app: alertmanager
    ports:
    - port: 9093
      targetPort: 9093
      name: http

# Grafana ConfigMap
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: grafana-config
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  data:
    grafana.ini: |
      [server]
      root_url = %(protocol)s://%(domain)s/grafana/
      serve_from_sub_path = true

      [security]
      admin_user = admin
      
      [auth]
      disable_login_form = false
      
      [users]
      allow_sign_up = false
      auto_assign_org_role = Viewer

# Grafana Deployment
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: grafana
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: grafana
    template:
      metadata:
        labels:
          app: grafana
      spec:
        securityContext:
          runAsNonRoot: true
          runAsUser: 472
          fsGroup: 472
        containers:
        - name: grafana
          image: grafana/grafana-oss:9.5.0
          ports:
            - containerPort: 3000
              name: http
          env:
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: grafana-admin
                  key: password
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: config
              mountPath: /etc/grafana/grafana.ini
              subPath: grafana.ini
            - name: storage
              mountPath: /var/lib/grafana
        volumes:
        - name: config
          configMap:
            name: grafana-config
        - name: storage
          emptyDir: {}

# Grafana Service
- apiVersion: v1
  kind: Service
  metadata:
    name: grafana
    namespace: monitoring
    labels:
      app.kubernetes.io/component: monitoring
      app.kubernetes.io/part-of: customer-success-ai
  spec:
    selector:
      app: grafana
    ports:
    - port: 3000
      targetPort: 3000
      name: http